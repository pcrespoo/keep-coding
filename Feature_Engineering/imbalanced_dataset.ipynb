{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset\n",
    "### References\n",
    "- https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "- Krish Naik Feature Engineering https://www.youtube.com/watch?v=pDw_JHHvj-0&list=PLZoTAELRMXVPwYGE2PXD3x0bfKnR0cJjN&index=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      284807\n",
       "V1        284807\n",
       "V2        284807\n",
       "V3        284807\n",
       "V4        284807\n",
       "V5        284807\n",
       "V6        284807\n",
       "V7        284807\n",
       "V8        284807\n",
       "V9        284807\n",
       "V10       284807\n",
       "V11       284807\n",
       "V12       284807\n",
       "V13       284807\n",
       "V14       284807\n",
       "V15       284807\n",
       "V16       284807\n",
       "V17       284807\n",
       "V18       284807\n",
       "V19       284807\n",
       "V20       284807\n",
       "V21       284807\n",
       "V22       284807\n",
       "V23       284807\n",
       "V24       284807\n",
       "V25       284807\n",
       "V26       284807\n",
       "V27       284807\n",
       "V28       284807\n",
       "Amount    284807\n",
       "Class     284807\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## no missing\n",
    "df.isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### 0 : no fraud\n",
    "##### 1: fraud\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separate into dependent(y) and independent features(x)\n",
    "x = df.drop('Class',axis=1)\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Techniques to handle imbalanced dataset\n",
    "1. Try different algorithms with different hyperparameters tuning\n",
    "2. Undersampling\n",
    "3. Oversampling\n",
    "4. SMOTE\n",
    "\n",
    "- As a rule of thumb , follow this workflow to handle imbalanced datasets:\n",
    "\n",
    "    - SMOTE --> Oversampling --> Ensemble and Hyperparameter Tuning\n",
    "    - Always have in mind the goal (reduce False Negatives or False Positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##split into train and test datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## instatiate the classifier\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'penalty': ['l1', 'l2'], 'solver': ['liblinear']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## set of parameters to pass into gridsearchCV\n",
    "params = {'C':10.0**np.arange(-2,3),'penalty':['l1','l2'],'solver':['liblinear']}\n",
    "## cross-validation\n",
    "cv = KFold(n_splits=5)\n",
    "## instatiate the gridsearchCV and fit it with train datasets\n",
    "grid = GridSearchCV(lr,params,cv=cv,scoring='f1_macro')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85272    11]\n",
      " [   58   102]]\n",
      "0.9991924440855307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85283\n",
      "           1       0.90      0.64      0.75       160\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.95      0.82      0.87     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Random Forest\n",
    "- Increase of precision and recall without any hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)\n",
    "y_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85276     7]\n",
      " [   36   124]]\n",
      "0.9994967405170698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85283\n",
      "           1       0.95      0.78      0.85       160\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.89      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Undersampling\n",
    "- reduce the occurence of the most representative class\n",
    "- pitfall: reduce the number of observations\n",
    "- rarely used! It's worth a try if dataset is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199032\n",
       "1       332\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "## make labels=1 around 80% of labels=0, so that 0 is reduced to 435 \n",
    "nm = NearMiss(sampling_strategy=0.8)\n",
    "x_train_nm, y_train_nm = nm.fit_sample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    415\n",
       "1    332\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_nm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train_nm,y_train_nm)\n",
    "y_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61544 23739]\n",
      " [    8   152]]\n",
      "0.7220720246246035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84     85283\n",
      "           1       0.01      0.95      0.01       160\n",
      "\n",
      "    accuracy                           0.72     85443\n",
      "   macro avg       0.50      0.84      0.43     85443\n",
      "weighted avg       1.00      0.72      0.84     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Oversampling\n",
    "- increase the occurence of the less representative label by adding exact points \n",
    "- better than undersampling technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "## make labels=1 around 50% of labels=0, so that 1 is increased to 99508\n",
    "os = RandomOverSampler(sampling_strategy=0.5)\n",
    "x_train_os,y_train_os = os.fit_sample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199032\n",
       "1     99516\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_os.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train_os,y_train_os)\n",
    "y_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85276     7]\n",
      " [   31   129]]\n",
      "0.9995552590615966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85283\n",
      "           1       0.95      0.81      0.87       160\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.90      0.94     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SMOTETomek\n",
    "- creates new points around the current ones (https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/)\n",
    "- pitfall: takes too long depending on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "sm = SMOTETomek(sampling_strategy=.75)\n",
    "x_train_sm, y_train_sm = sm.fit_sample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train_sm,y_train_sm)\n",
    "y_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
